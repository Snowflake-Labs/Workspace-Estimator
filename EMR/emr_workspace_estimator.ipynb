{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e881767c-f2c6-43ea-b25a-0055083b4084",
   "metadata": {},
   "source": [
    "# EMR Serverless estimator\n",
    "\n",
    "Welcome to the EMR serverless estimator, follow the steps to get the estimation files.\n",
    "\n",
    "1. Initializes configuration parameters (AWS region, user email, company, data retrieval period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8e6d9-4eba-4c9e-8f00-69fe1a3d5a93",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_name = \"\"\n",
    "email = \"\"\n",
    "company = \"\"\n",
    "runs_for_last_days = 15  # Default 15 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab8f83-7c8d-4a5a-ad91-329a76b421c5",
   "metadata": {},
   "source": [
    "# Imports and constants\n",
    "\n",
    "2. Imports necessary Python libraries for data manipulation, AWS interaction, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce4bea-89fe-4abb-8782-281ef720216b",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import logging\n",
    "import uuid\n",
    "import zipfile\n",
    "\n",
    "from collections.abc import Iterator\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df279142",
   "metadata": {},
   "source": [
    "3. Defines string constants for AWS data fields and establishes connections to AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda92fa3-36ce-4584-80ba-1328d22669d9",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# String literal constants\n",
    "APPLICATION_ID_LITERAL = \"applicationId\"\n",
    "NAME_LITERAL = \"name\"\n",
    "TYPE_LITERAL = \"type\"\n",
    "STATE_LITERAL = \"state\"\n",
    "ARCHITECTURE_LITERAL = \"architecture\"\n",
    "CREATED_AT_LITERAL = \"createdAt\"\n",
    "UPDATED_AT_LITERAL = \"updatedAt\"\n",
    "INITIAL_CAPACITY_LITERAL = \"initialCapacity\"\n",
    "EXECUTOR_LITERAL = \"Executor\"\n",
    "WORKER_COUNT_LITERAL = \"workerCount\"\n",
    "WORKER_CONFIGURATION_LITERAL = \"workerConfiguration\"\n",
    "CPU_LITERAL = \"cpu\"\n",
    "MEMORY_LITERAL = \"memory\"\n",
    "DISK_LITERAL = \"disk\"\n",
    "DRIVER_LITERAL = \"Driver\"\n",
    "MAXIMUM_CAPACITY_LITERAL = \"maximumCapacity\"\n",
    "CONFIG_OVERRIDES_LITERAL = \"configurationOverrides\"\n",
    "MONITORING_CONFIG_LITERAL = \"monitoringConfiguration\"\n",
    "S3_MONITORING_CONFIG_LITERAL = \"s3MonitoringConfiguration\"\n",
    "MANAGED_PERSISTENCE_MONITORING_CONFIG_LITERAL = \"managedPersistenceMonitoringConfiguration\"\n",
    "CLOUD_WATCH_LOGGING_CONFIG_LITERAL = \"cloudWatchLoggingConfiguration\"\n",
    "ENABLED_LITERAL = \"enabled\"\n",
    "JOB_RUN_ID_LITERAL = \"jobRunId\"\n",
    "MODE_LITERAL = \"mode\"\n",
    "ATTEMPT_LITERAL = \"attempt\"\n",
    "STARTED_AT_LITERAL = \"startedAt\"\n",
    "ENDED_AT_LITERAL = \"endedAt\"\n",
    "QUEUED_DURATION_MS_LITERAL = \"queuedDurationMilliseconds\"\n",
    "TOTAL_RESOURCE_UTILIZATION_LITERAL = \"totalResourceUtilization\"\n",
    "VCPU_HOUR_LITERAL = \"vCPUHour\"\n",
    "MEMORY_GB_HOUR_LITERAL = \"memoryGBHour\"\n",
    "STORAGE_GB_HOUR_LITERAL = \"storageGBHour\"\n",
    "BILLED_RESOURCE_UTILIZATION_LITERAL = \"billedResourceUtilization\"\n",
    "TOTAL_EXECUTION_DURATION_SECONDS_LITERAL = \"totalExecutionDurationSeconds\"\n",
    "EXECUTION_TIMEOUT_MINUTES_LITERAL = \"executionTimeoutMinutes\"\n",
    "JOB_TYPE_LITERAL = \"job_type\"\n",
    "S3_MONITORING_ENABLED_LITERAL = \"s3_monitoring_enabled\"\n",
    "MP_MONITORING_ENABLED_LITERAL = \"mp_monitoring_enabled\"\n",
    "CLOUD_WATCH_ENABLED_LITERAL = \"cloud_watch_enabled\"\n",
    "KEYS_LITERAL = \"Keys\"\n",
    "METRICS_LITERAL = \"Metrics\"\n",
    "UNBLENDED_COST_LITERAL = \"UnblendedCost\"\n",
    "AMOUNT_LITERAL = \"Amount\"\n",
    "UNIT_LITERAL = \"Unit\"\n",
    "GROUPS_LITERAL = \"Groups\"\n",
    "TIME_PERIOD_LITERAL = \"TimePeriod\"\n",
    "START_LITERAL = \"Start\"\n",
    "\n",
    "# Dictionary key constants\n",
    "APP_ID_KEY = \"application_id\"\n",
    "APP_NAME_KEY = \"application_name\"\n",
    "APP_TYPE_KEY = \"application_type\"\n",
    "APP_STATE_KEY = \"application_state\"\n",
    "ARCHITECTURE_KEY = \"architecture\"\n",
    "CREATED_AT_KEY = \"created_at\"\n",
    "UPDATED_AT_KEY = \"updated_at\"\n",
    "EXECUTOR_WORKER_COUNT_KEY = \"executor_worker_count\"\n",
    "EXECUTOR_WORKER_CPU_KEY = \"executor_worker_cpu\"\n",
    "EXECUTOR_WORKER_MEMORY_KEY = \"executor_worker_memory\"\n",
    "EXECUTOR_WORKER_DISK_KEY = \"executor_worker_disk\"\n",
    "DRIVER_WORKER_COUNT_KEY = \"driver_worker_count\"\n",
    "DRIVER_WORKER_CPU_KEY = \"driver_worker_cpu\"\n",
    "DRIVER_WORKER_MEMORY_KEY = \"driver_worker_memory\"\n",
    "DRIVER_WORKER_DISK_KEY = \"driver_worker_disk\"\n",
    "MAXIMUM_CPU_KEY = \"maximum_cpu\"\n",
    "MAXIMUM_MEMORY_KEY = \"maximum_memory\"\n",
    "MAXIMUM_DISK_KEY = \"maximum_disk\"\n",
    "JOB_RUN_ID_KEY = \"job_run_id\"\n",
    "JOB_NAME_KEY = \"job_name\"\n",
    "JOB_MODE_KEY = \"job_mode\"\n",
    "JOB_STATE_KEY = \"job_state\"\n",
    "ATTEMPT_KEY = \"attempt\"\n",
    "STARTED_AT_KEY = \"started_at\"\n",
    "ENDED_AT_KEY = \"ended_at\"\n",
    "QUEUED_DURATION_MS_KEY = \"queued_duration_milliseconds\"\n",
    "TRU_VCPU_HOUR_KEY = \"tru_vcpu_hour\"\n",
    "TRU_MEMORY_GB_HOUR_KEY = \"tru_memory_gb_hour\"\n",
    "TRU_STORAGE_GB_HOUR_KEY = \"tru_storage_gb_hour\"\n",
    "BRU_VCPU_HOUR_KEY = \"bru_vcpu_hour\"\n",
    "BRU_MEMORY_GB_HOUR_KEY = \"bru_memory_gb_hour\"\n",
    "BRU_STORAGE_GB_HOUR_KEY = \"bru_storage_gb_hour\"\n",
    "TOTAL_EXECUTION_SECONDS_KEY = \"total_execution_duration_seconds\"\n",
    "EXECUTION_TIMEOUT_MINUTES_KEY = \"execution_timeout_minutes\"\n",
    "JOB_TYPE_KEY_DICT = \"job_type\"\n",
    "S3_MONITORING_ENABLED_KEY_DICT = \"s3_monitoring_enabled\"\n",
    "MP_MONITORING_ENABLED_KEY_DICT = \"mp_monitoring_enabled\"\n",
    "CLOUD_WATCH_ENABLED_KEY_DICT = \"cloud_watch_enabled\"\n",
    "USAGE_TYPE_KEY = \"usage_type\"\n",
    "AMOUNT_KEY = \"amount\"\n",
    "UNIT_KEY = \"unit\"\n",
    "DATE_KEY = \"date\"\n",
    "\n",
    "# Execution details constants\n",
    "NOTEBOOK_VERSION = \"0.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc992a",
   "metadata": {},
   "source": [
    "# Logging Setup\n",
    "4. This section configures the \"emr_serverless_estimator\" logger to display informational messages, warnings, and errors directly in your notebook's output, aiding in monitoring the EMR Serverless estimation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LOG_LEVEL = logging.INFO\n",
    "\n",
    "logger = logging.getLogger(\"emr_serverless_estimator\")\n",
    "logger.setLevel(MIN_LOG_LEVEL)\n",
    "\n",
    "if not logger.handlers:\n",
    "    formatter = logging.Formatter(\n",
    "        \"{asctime} - {name} - {levelname} - {message}\",\n",
    "        style=\"{\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(MIN_LOG_LEVEL)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b507c6-1afa-4d6f-8520-7cf5677a363c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T21:39:13.508539Z",
     "iopub.status.busy": "2025-05-12T21:39:13.508096Z",
     "iopub.status.idle": "2025-05-12T21:39:13.512948Z",
     "shell.execute_reply": "2025-05-12T21:39:13.512084Z",
     "shell.execute_reply.started": "2025-05-12T21:39:13.508506Z"
    },
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "source": [
    "# EMR Serverless Estimator Manager\n",
    "\n",
    "5. Defines the **EMRSEstimatorManager** class to encapsulate estimation logic and data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4adcc0-6f2a-4675-9fd6-2698787d3a60",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EMRSEstimatorManager:\n",
    "    \"\"\"Manage EMR Serverless applications, job runs, and cost estimations.\n",
    "\n",
    "    Attributes:\n",
    "        region_name (str): AWS region name.\n",
    "        email (str): User email for identification.\n",
    "        company (str): Company name for identification.\n",
    "        execution_id (str): Unique identifier for the execution.\n",
    "        application_list (list): List of applications.\n",
    "        job_runs_info (list): List of job runs information.\n",
    "        application_costs_list (list): List of application costs.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        region_name: str,\n",
    "        email: str,\n",
    "        company: str,\n",
    "    ):\n",
    "        \"\"\"Initialize the EMRSEstimatorManager with region, email, and company.\n",
    "\n",
    "        Args:\n",
    "            region_name (str): AWS region name.\n",
    "            email (str): User email.\n",
    "            company (str): Company name.\n",
    "\n",
    "        \"\"\"\n",
    "        self.application_list = []\n",
    "        self.job_runs_info = []\n",
    "        self.region_name = region_name\n",
    "        self.email = email\n",
    "        self.company = company\n",
    "        self.execution_id = str(uuid.uuid4())\n",
    "        self.application_costs_list = []\n",
    "\n",
    "    def add_application(self, app_info: dict):\n",
    "        \"\"\"Add an application to the application list.\n",
    "\n",
    "        Args:\n",
    "            app_info (dict): Dictionary containing application details.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            new_application = {\n",
    "                APP_ID_KEY: app_info.get(APPLICATION_ID_LITERAL, \"N/A\"),\n",
    "                APP_NAME_KEY: app_info.get(NAME_LITERAL, \"N/A\"),\n",
    "                APP_TYPE_KEY: app_info.get(TYPE_LITERAL, \"N/A\"),\n",
    "                APP_STATE_KEY: app_info.get(STATE_LITERAL, \"N/A\"),\n",
    "                ARCHITECTURE_KEY: app_info.get(ARCHITECTURE_LITERAL, \"N/A\"),\n",
    "                CREATED_AT_KEY: str(app_info.get(CREATED_AT_LITERAL, \"N/A\")),\n",
    "                UPDATED_AT_KEY: str(app_info.get(UPDATED_AT_LITERAL, \"N/A\")),\n",
    "                EXECUTOR_WORKER_COUNT_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(EXECUTOR_LITERAL, {})\n",
    "                .get(WORKER_COUNT_LITERAL, \"N/A\"),\n",
    "                EXECUTOR_WORKER_CPU_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(EXECUTOR_LITERAL, {})\n",
    "                .get(WORKER_CONFIGURATION_LITERAL, {})\n",
    "                .get(CPU_LITERAL, \"N/A\"),\n",
    "                EXECUTOR_WORKER_MEMORY_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(EXECUTOR_LITERAL, {})\n",
    "                .get(WORKER_CONFIGURATION_LITERAL, {})\n",
    "                .get(MEMORY_LITERAL, \"N/A\"),\n",
    "                EXECUTOR_WORKER_DISK_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(EXECUTOR_LITERAL, {})\n",
    "                .get(WORKER_CONFIGURATION_LITERAL, {})\n",
    "                .get(DISK_LITERAL, \"N/A\"),\n",
    "                DRIVER_WORKER_COUNT_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(DRIVER_LITERAL, {})\n",
    "                .get(WORKER_COUNT_LITERAL, \"N/A\"),\n",
    "                DRIVER_WORKER_CPU_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(DRIVER_LITERAL, {})\n",
    "                .get(WORKER_CONFIGURATION_LITERAL, {})\n",
    "                .get(CPU_LITERAL, \"N/A\"),\n",
    "                DRIVER_WORKER_MEMORY_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(DRIVER_LITERAL, {})\n",
    "                .get(WORKER_CONFIGURATION_LITERAL, {})\n",
    "                .get(MEMORY_LITERAL, \"N/A\"),\n",
    "                DRIVER_WORKER_DISK_KEY: app_info.get(INITIAL_CAPACITY_LITERAL, {})\n",
    "                .get(DRIVER_LITERAL, {})\n",
    "                .get(WORKER_CONFIGURATION_LITERAL, {})\n",
    "                .get(DISK_LITERAL, \"N/A\"),\n",
    "                MAXIMUM_CPU_KEY: app_info.get(MAXIMUM_CAPACITY_LITERAL, {}).get(\n",
    "                    CPU_LITERAL,\n",
    "                    \"N/A\",\n",
    "                ),\n",
    "                MAXIMUM_MEMORY_KEY: app_info.get(MAXIMUM_CAPACITY_LITERAL, {}).get(\n",
    "                    MEMORY_LITERAL,\n",
    "                    \"N/A\",\n",
    "                ),\n",
    "                MAXIMUM_DISK_KEY: app_info.get(MAXIMUM_CAPACITY_LITERAL, {}).get(\n",
    "                    DISK_LITERAL,\n",
    "                    \"N/A\",\n",
    "                ),\n",
    "            }\n",
    "            self.application_list.append(new_application)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error adding application: {e}\")\n",
    "\n",
    "    def add_job_run(self, job_info: dict, job_type: str):\n",
    "        \"\"\"Add a job run to the job runs list.\n",
    "\n",
    "        Args:\n",
    "            job_info (dict): Dictionary containing job run details.\n",
    "            job_type (str): Type of the job run.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            new_job_run = {\n",
    "                JOB_RUN_ID_KEY: job_info.get(JOB_RUN_ID_LITERAL, \"N/A\"),\n",
    "                APP_ID_KEY: job_info.get(APPLICATION_ID_LITERAL, \"N/A\"),\n",
    "                JOB_NAME_KEY: job_info.get(NAME_LITERAL, \"N/A\"),\n",
    "                JOB_MODE_KEY: job_info.get(MODE_LITERAL, \"N/A\"),\n",
    "                CREATED_AT_KEY: job_info.get(CREATED_AT_LITERAL, \"N/A\"),\n",
    "                UPDATED_AT_KEY: job_info.get(UPDATED_AT_LITERAL, \"N/A\"),\n",
    "                JOB_TYPE_KEY_DICT: job_type,\n",
    "                S3_MONITORING_ENABLED_KEY_DICT: job_info.get(\n",
    "                    CONFIG_OVERRIDES_LITERAL,\n",
    "                    {},\n",
    "                )\n",
    "                .get(MONITORING_CONFIG_LITERAL, {})\n",
    "                .get(S3_MONITORING_CONFIG_LITERAL, {})\n",
    "                .get(ENABLED_LITERAL, \"N/A\"),\n",
    "                MP_MONITORING_ENABLED_KEY_DICT: job_info.get(\n",
    "                    CONFIG_OVERRIDES_LITERAL,\n",
    "                    {},\n",
    "                )\n",
    "                .get(MONITORING_CONFIG_LITERAL, {})\n",
    "                .get(MANAGED_PERSISTENCE_MONITORING_CONFIG_LITERAL, {})\n",
    "                .get(ENABLED_LITERAL, \"N/A\"),\n",
    "                CLOUD_WATCH_ENABLED_KEY_DICT: job_info.get(CONFIG_OVERRIDES_LITERAL, {})\n",
    "                .get(MONITORING_CONFIG_LITERAL, {})\n",
    "                .get(CLOUD_WATCH_LOGGING_CONFIG_LITERAL, {})\n",
    "                .get(ENABLED_LITERAL, \"N/A\"),\n",
    "                ATTEMPT_KEY: job_info.get(ATTEMPT_LITERAL, \"N/A\"),\n",
    "                JOB_STATE_KEY: job_info.get(STATE_LITERAL, \"N/A\"),\n",
    "                STARTED_AT_KEY: job_info.get(STARTED_AT_LITERAL, \"N/A\"),\n",
    "                ENDED_AT_KEY: job_info.get(ENDED_AT_LITERAL, \"N/A\"),\n",
    "                QUEUED_DURATION_MS_KEY: job_info.get(QUEUED_DURATION_MS_LITERAL, \"N/A\"),\n",
    "                TRU_VCPU_HOUR_KEY: job_info.get(\n",
    "                    TOTAL_RESOURCE_UTILIZATION_LITERAL,\n",
    "                    {},\n",
    "                ).get(VCPU_HOUR_LITERAL, \"N/A\"),\n",
    "                TRU_MEMORY_GB_HOUR_KEY: job_info.get(\n",
    "                    TOTAL_RESOURCE_UTILIZATION_LITERAL,\n",
    "                    {},\n",
    "                ).get(MEMORY_GB_HOUR_LITERAL, \"N/A\"),\n",
    "                TRU_STORAGE_GB_HOUR_KEY: job_info.get(\n",
    "                    TOTAL_RESOURCE_UTILIZATION_LITERAL,\n",
    "                    {},\n",
    "                ).get(STORAGE_GB_HOUR_LITERAL, \"N/A\"),\n",
    "                BRU_VCPU_HOUR_KEY: job_info.get(\n",
    "                    BILLED_RESOURCE_UTILIZATION_LITERAL,\n",
    "                    {},\n",
    "                ).get(VCPU_HOUR_LITERAL, \"N/A\"),\n",
    "                BRU_MEMORY_GB_HOUR_KEY: job_info.get(\n",
    "                    BILLED_RESOURCE_UTILIZATION_LITERAL,\n",
    "                    {},\n",
    "                ).get(MEMORY_GB_HOUR_LITERAL, \"N/A\"),\n",
    "                BRU_STORAGE_GB_HOUR_KEY: job_info.get(\n",
    "                    BILLED_RESOURCE_UTILIZATION_LITERAL,\n",
    "                    {},\n",
    "                ).get(STORAGE_GB_HOUR_LITERAL, \"N/A\"),\n",
    "                TOTAL_EXECUTION_SECONDS_KEY: job_info.get(\n",
    "                    TOTAL_EXECUTION_DURATION_SECONDS_LITERAL,\n",
    "                    \"N/A\",\n",
    "                ),\n",
    "                EXECUTION_TIMEOUT_MINUTES_KEY: job_info.get(\n",
    "                    EXECUTION_TIMEOUT_MINUTES_LITERAL,\n",
    "                    \"N/A\",\n",
    "                ),\n",
    "            }\n",
    "            self.job_runs_info.append(new_job_run)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error adding job run: {e}\")\n",
    "\n",
    "    def add_application_cost_list(self, cost_list: list, application_id: str) -> None:\n",
    "        \"\"\"Add cost information for an application.\n",
    "\n",
    "        Args:\n",
    "            cost_list (list): Dictionary containing cost details.\n",
    "            application_id (str): ID of the application.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for cost in cost_list:\n",
    "                start_period = cost.get(TIME_PERIOD_LITERAL, {}).get(\n",
    "                    START_LITERAL,\n",
    "                    \"N/A\",\n",
    "                )\n",
    "                groups = cost.get(GROUPS_LITERAL, [])\n",
    "\n",
    "                if not groups:\n",
    "                    new_cost = {\n",
    "                        APP_ID_KEY: application_id,\n",
    "                        DATE_KEY: start_period,\n",
    "                        USAGE_TYPE_KEY: \"\",\n",
    "                        AMOUNT_KEY: 0,\n",
    "                        UNIT_KEY: \"USD\",\n",
    "                    }\n",
    "                    self.application_costs_list.append(new_cost)\n",
    "                else:\n",
    "                    for group in groups:\n",
    "                        keys = group.get(KEYS_LITERAL, [])\n",
    "                        concatenated_keys = \" | \".join(key for key in keys)\n",
    "                        costs_object = group.get(METRICS_LITERAL, {}).get(\n",
    "                            UNBLENDED_COST_LITERAL,\n",
    "                            {},\n",
    "                        )\n",
    "                        amount = costs_object.get(AMOUNT_LITERAL, \"0\")\n",
    "                        unit = costs_object.get(UNIT_LITERAL, \"N/A\")\n",
    "                        new_cost = {\n",
    "                            APP_ID_KEY: application_id,\n",
    "                            DATE_KEY: start_period,\n",
    "                            USAGE_TYPE_KEY: concatenated_keys,\n",
    "                            AMOUNT_KEY: amount,\n",
    "                            UNIT_KEY: unit,\n",
    "                        }\n",
    "                        self.application_costs_list.append(new_cost)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error adding application cost list: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_buffer_output(data: pd.DataFrame) -> io.StringIO:\n",
    "        \"\"\"Convert a DataFrame to a CSV buffer.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): DataFrame to convert.\n",
    "\n",
    "        Returns:\n",
    "            io.StringIO: Buffer containing the CSV data.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            buffer = io.StringIO()\n",
    "            data.to_csv(buffer, index=False, encoding=\"utf-8\")\n",
    "            buffer.seek(0)\n",
    "            return buffer\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error getting buffer output: {e}\")\n",
    "\n",
    "    def get_execution_info(self) -> dict:\n",
    "        \"\"\"Retrieve execution metadata.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing execution metadata.\n",
    "\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"execution_id\": self.execution_id,\n",
    "            \"email\": self.email,\n",
    "            \"company\": self.company,\n",
    "            \"region\": self.region_name,\n",
    "            \"version\": NOTEBOOK_VERSION,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "            \"runs_for_last_days\": runs_for_last_days,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_output_config() -> dict:\n",
    "        \"\"\"Retrieve the output configuration.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing output configuration data.\n",
    "\n",
    "        \"\"\"\n",
    "        output_config = {\n",
    "            \"title\": \"Download Analysis Data\",\n",
    "            \"execution_detail_name_file\": \"execution_detail.csv\",\n",
    "            \"application_list_name_file\": \"application_list.csv\",\n",
    "            \"application_costs_list_name_file\": \"application_costs_list.csv\",\n",
    "            \"job_runs_list_name_file\": \"job_runs_list.csv\",\n",
    "            \"job_runs_attempts_name_file\": \"job_runs_attempts.csv\",\n",
    "            \"job_runs_list_columns\": [\n",
    "                JOB_RUN_ID_KEY,\n",
    "                APP_ID_KEY,\n",
    "                JOB_NAME_KEY,\n",
    "                JOB_MODE_KEY,\n",
    "                CREATED_AT_KEY,\n",
    "                UPDATED_AT_KEY,\n",
    "                JOB_TYPE_KEY_DICT,\n",
    "                S3_MONITORING_ENABLED_KEY_DICT,\n",
    "                MP_MONITORING_ENABLED_KEY_DICT,\n",
    "                CLOUD_WATCH_ENABLED_KEY_DICT,\n",
    "            ],\n",
    "            \"job_runs_attempts_columns\": [\n",
    "                JOB_RUN_ID_KEY,\n",
    "                APP_ID_KEY,\n",
    "                ATTEMPT_KEY,\n",
    "                JOB_STATE_KEY,\n",
    "                STARTED_AT_KEY,\n",
    "                ENDED_AT_KEY,\n",
    "                QUEUED_DURATION_MS_KEY,\n",
    "                TRU_VCPU_HOUR_KEY,\n",
    "                TRU_MEMORY_GB_HOUR_KEY,\n",
    "                TRU_STORAGE_GB_HOUR_KEY,\n",
    "                BRU_VCPU_HOUR_KEY,\n",
    "                BRU_MEMORY_GB_HOUR_KEY,\n",
    "                BRU_STORAGE_GB_HOUR_KEY,\n",
    "                TOTAL_EXECUTION_SECONDS_KEY,\n",
    "                EXECUTION_TIMEOUT_MINUTES_KEY,\n",
    "            ],\n",
    "        }\n",
    "        return output_config\n",
    "\n",
    "    @staticmethod\n",
    "    def compress_data(\n",
    "        output_config: dict,\n",
    "        execution_info_buffer: io.StringIO,\n",
    "        application_list_buffer: io.StringIO,\n",
    "        application_costs_list_buffer: io.StringIO,\n",
    "        job_runs_list_buffer: io.StringIO,\n",
    "        job_runs_attempts_buffer: io.StringIO,\n",
    "    ) -> str:\n",
    "        \"\"\"Compresses multiple CSV buffers into a single ZIP file and encodes it in Base64.\n",
    "\n",
    "        Args:\n",
    "            output_config (dict): Configuration dictionary containing file names for the ZIP archive.\n",
    "            execution_info_buffer (io.StringIO): Buffer containing execution metadata in CSV format.\n",
    "            application_list_buffer (io.StringIO): Buffer containing application list data in CSV format.\n",
    "            application_costs_list_buffer (io.StringIO): Buffer containing application cost data in CSV format.\n",
    "            job_runs_list_buffer (io.StringIO): Buffer containing job runs list data in CSV format.\n",
    "            job_runs_attempts_buffer (io.StringIO): Buffer containing job runs attempts data in CSV format.\n",
    "\n",
    "        Returns:\n",
    "            str: Base64-encoded string of the compressed ZIP file.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            zip_buffer = io.BytesIO()\n",
    "            with zipfile.ZipFile(zip_buffer, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "                zf.writestr(\n",
    "                    output_config[\"execution_detail_name_file\"],\n",
    "                    execution_info_buffer.getvalue(),\n",
    "                )\n",
    "                zf.writestr(\n",
    "                    output_config[\"application_list_name_file\"],\n",
    "                    application_list_buffer.getvalue(),\n",
    "                )\n",
    "                zf.writestr(\n",
    "                    output_config[\"application_costs_list_name_file\"],\n",
    "                    application_costs_list_buffer.getvalue(),\n",
    "                )\n",
    "                zf.writestr(\n",
    "                    output_config[\"job_runs_list_name_file\"],\n",
    "                    job_runs_list_buffer.getvalue(),\n",
    "                )\n",
    "                zf.writestr(\n",
    "                    output_config[\"job_runs_attempts_name_file\"],\n",
    "                    job_runs_attempts_buffer.getvalue(),\n",
    "                )\n",
    "\n",
    "            zip_bytes = zip_buffer.getvalue()\n",
    "            b64 = base64.b64encode(zip_bytes).decode()\n",
    "            return b64\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error compressing data: {e}\")\n",
    "\n",
    "    def show_output(self, output_file_name: str = None) -> None:\n",
    "        \"\"\"Generate and displays a downloadable ZIP file with analysis data.\n",
    "\n",
    "        Args:\n",
    "            output_file_name (str, optional): Name of the output ZIP file.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if output_file_name is None:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_file_name = f\"emr_we_output_{timestamp}.zip\"\n",
    "\n",
    "            output_config = self.get_output_config()\n",
    "\n",
    "            application_df = pd.DataFrame(self.application_list)\n",
    "            application_list_buffer = self.get_buffer_output(application_df)\n",
    "\n",
    "            application_costs_list_buffer = self.get_buffer_output(\n",
    "                pd.DataFrame(self.application_costs_list),\n",
    "            )\n",
    "\n",
    "            job_runs_info_df = pd.DataFrame(self.job_runs_info)\n",
    "            job_runs_list_df = pd.DataFrame()\n",
    "            job_runs_attempts_df = pd.DataFrame()\n",
    "\n",
    "            if not job_runs_info_df.empty:\n",
    "                job_runs_list_df = job_runs_info_df[output_config[\"job_runs_list_columns\"]].drop_duplicates(\n",
    "                    subset=[JOB_RUN_ID_KEY],\n",
    "                    keep=\"first\",\n",
    "                )\n",
    "\n",
    "                job_runs_attempts_df = job_runs_info_df[output_config[\"job_runs_attempts_columns\"]]\n",
    "\n",
    "            job_runs_list_buffer = self.get_buffer_output(job_runs_list_df)\n",
    "            job_runs_attempts_buffer = self.get_buffer_output(job_runs_attempts_df)\n",
    "\n",
    "            total_applications = application_df.shape[0]\n",
    "            total_job_runs = job_runs_list_df.shape[0]\n",
    "            total_job_runs_attempts = job_runs_attempts_df.shape[0]\n",
    "            execution_info_df = pd.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        **self.get_execution_info(),\n",
    "                        \"total_applications\": total_applications,\n",
    "                        \"total_job_runs\": total_job_runs,\n",
    "                        \"total_job_runs_attempts\": total_job_runs_attempts,\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "            execution_info_buffer = self.get_buffer_output(execution_info_df)\n",
    "\n",
    "            payload = self.compress_data(\n",
    "                output_config,\n",
    "                execution_info_buffer,\n",
    "                application_list_buffer,\n",
    "                application_costs_list_buffer,\n",
    "                job_runs_list_buffer,\n",
    "                job_runs_attempts_buffer,\n",
    "            )\n",
    "\n",
    "            html = (\n",
    "                f'<html><div style=\"display:flex;justify-content: center;\">'\n",
    "                f'<a download=\"{output_file_name}\" '\n",
    "                f'href=\"data:application/zip;base64,{payload}\" '\n",
    "                f'target=\"_blank\">'\n",
    "                f'<button style=\"background-color:#249edc;color: #fff;'\n",
    "                f\"border:1px solid #249edc;cursor:pointer;border-radius:45px;\"\n",
    "                f'font-weight:800;line-height:18px;padding: 8px 16px\" '\n",
    "                f'type=\"button\">{output_config.get(\"title\")}</button>'\n",
    "                f\"</a></div></html>\"\n",
    "            )\n",
    "            display(HTML(html))\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error showing output: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7502c8-4b99-451a-80c0-c6e257d17988",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "\n",
    "6. Defines utility functions for retrieving data from AWS (applications, job runs, costs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5628712-2049-44c3-b9f8-d946bc62fb45",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_application_costs(arn) -> list:\n",
    "    \"\"\"Retrieve cost information for a specific application.\n",
    "\n",
    "    Args:\n",
    "        arn (str): ARN of the application.\n",
    "\n",
    "    Returns:\n",
    "        list: List of cost details by time period.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        now = datetime.now(timezone.utc)  # noqa: UP017\n",
    "        start_date = (datetime.now() - timedelta(days=14)).strftime(\"%Y-%m-%d\")\n",
    "        end_date = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        cost = cost_explorer_client.get_cost_and_usage_with_resources(\n",
    "            Granularity=\"DAILY\",\n",
    "            Filter={\n",
    "                \"Dimensions\": {\"Key\": \"RESOURCE_ID\", \"Values\": [arn]},\n",
    "            },\n",
    "            TimePeriod={\"Start\": start_date, \"End\": end_date},\n",
    "            Metrics=[\"UnblendedCost\"],\n",
    "            GroupBy=[\n",
    "                {\n",
    "                    \"Type\": \"DIMENSION\",\n",
    "                    \"Key\": \"USAGE_TYPE\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        return cost.get(\"ResultsByTime\", [])\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error getting application costs: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def list_applications(\n",
    "    runs_for_last_days_ago: datetime,\n",
    ") -> Iterator[str]:\n",
    "    \"\"\"List applications updated within the specified time period.\n",
    "\n",
    "    Args:\n",
    "        runs_for_last_days_ago (datetime): Time period in days.\n",
    "\n",
    "    Yields:\n",
    "        str: Application ID.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        paginator = emr_serverless_client.get_paginator(\"list_applications\")\n",
    "        for page in paginator.paginate():\n",
    "            if \"applications\" in page:\n",
    "                for app in page[\"applications\"]:\n",
    "                    is_valid_date = \"updatedAt\" in app and app[\"updatedAt\"] >= runs_for_last_days_ago\n",
    "                    if is_valid_date:\n",
    "                        application_costs = get_application_costs(app[\"arn\"])\n",
    "                        estimator_manager.add_application_cost_list(\n",
    "                            application_costs,\n",
    "                            app[\"id\"],\n",
    "                        )\n",
    "                        app_info = emr_serverless_client.get_application(\n",
    "                            applicationId=app[\"id\"],\n",
    "                        )\n",
    "                        estimator_manager.add_application(app_info[\"application\"])\n",
    "                        yield app[\"id\"]\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error listing applications: {e}\")\n",
    "\n",
    "\n",
    "def list_jobs(application_id: str, runs_for_last_days_ago: datetime) -> Iterator[dict]:\n",
    "    \"\"\"List job runs for a specific application within the specified time period.\n",
    "\n",
    "    Args:\n",
    "        application_id (str): ID of the application.\n",
    "        runs_for_last_days_ago (datetime): Time period in days.\n",
    "\n",
    "    Yields:\n",
    "        dict: Job run details.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        paginator = emr_serverless_client.get_paginator(\"list_job_runs\")\n",
    "        for page in paginator.paginate(applicationId=application_id):\n",
    "            if \"jobRuns\" in page:\n",
    "                for job_run in page[\"jobRuns\"]:\n",
    "                    is_valid_date = \"updatedAt\" in job_run and job_run[\"updatedAt\"] >= runs_for_last_days_ago\n",
    "                    if is_valid_date:\n",
    "                        yield job_run\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error listing job runs: {e}\")\n",
    "\n",
    "\n",
    "def add_job_run_info(job_run: dict, job_attempt: int):\n",
    "    \"\"\"Process information for a specific job run attempt.\n",
    "\n",
    "    Args:\n",
    "        job_run (dict): Dictionary containing job run details.\n",
    "        job_attempt (int): Attempt number of the job run.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        application_id = job_run.get(\"applicationId\", \"N/A\")\n",
    "        job_run_id = job_run.get(\"id\", \"N/A\")\n",
    "        response = emr_serverless_client.get_job_run(\n",
    "            applicationId=application_id,\n",
    "            jobRunId=job_run_id,\n",
    "            attempt=job_attempt,\n",
    "        )\n",
    "        if \"jobRun\" in response:\n",
    "            job_info = response[\"jobRun\"]\n",
    "            job_type = job_run.get(\"type\", \"N/A\")\n",
    "            estimator_manager.add_job_run(job_info, job_type)\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error adding job run info: {e}\")\n",
    "\n",
    "\n",
    "def validate_user_info() -> bool:\n",
    "    \"\"\"Validate the user information required for the application.\n",
    "\n",
    "    Checks if the region, email, company, and the number of days for job runs\n",
    "    are properly configured. Logs errors or warnings for invalid or missing values.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the user information is valid, False otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "    is_valid = True\n",
    "    if region_name == \"\":\n",
    "        logger.error(\"Region is empty. Please provide a valid region.\")\n",
    "        is_valid = False\n",
    "    if runs_for_last_days < 1:\n",
    "        logger.error(\"Runs for last days must be greater than 0.\")\n",
    "        is_valid = False\n",
    "    if email == \"\":\n",
    "        logger.warning(\"Email is empty. Please provide a valid email.\")\n",
    "    if company == \"\":\n",
    "        logger.warning(\"Company is empty. Please provide a valid company.\")\n",
    "\n",
    "    return is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a819d-0115-4961-a903-e99f5bc59db2",
   "metadata": {},
   "source": [
    "# Generate estimation\n",
    "\n",
    "7. Executes the main estimation workflow: instantiates the manager, retrieves data, and generates the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3b26a-2338-49b5-8154-0246f2a8904e",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::631484165566:role/workspace-estimator-test",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if validate_user_info():\n",
    "    emr_serverless_client = boto3.client(\"emr-serverless\", region_name=region_name)\n",
    "    cost_explorer_client = boto3.client(\"ce\", region_name=region_name)\n",
    "\n",
    "    estimator_manager = EMRSEstimatorManager(region_name, email, company)\n",
    "    now = datetime.now(timezone.utc)  # noqa: UP017\n",
    "    runs_for_last_days_ago = now - timedelta(days=runs_for_last_days)\n",
    "\n",
    "    logger.info(\"Retrieving data...\")\n",
    "    logger.info(f\"Start date: {runs_for_last_days_ago.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    count_apps = 0\n",
    "    count_jobs = 0\n",
    "    for app_id in list_applications(runs_for_last_days_ago):\n",
    "        for job_run in list_jobs(app_id, runs_for_last_days_ago):\n",
    "            attempts = job_run.get(\"attempt\")\n",
    "            for attempt in range(attempts):\n",
    "                add_job_run_info(job_run, attempt + 1)\n",
    "            count_jobs += 1\n",
    "        count_apps += 1\n",
    "\n",
    "    logger.info(f\"Total applications: {count_apps}\")\n",
    "    logger.info(f\"Total job runs: {count_jobs}\")\n",
    "\n",
    "    estimator_manager.show_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3_toledo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
